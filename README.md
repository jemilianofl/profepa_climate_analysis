# ğŸŒ¦ï¸ Sistema de AnÃ¡lisis ClimatolÃ³gico y PredicciÃ³n EstocÃ¡stica (SACP)
### PenÃ­nsula de YucatÃ¡n, MÃ©xico

![Python](https://img.shields.io/badge/Python-3.10%2B-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Streamlit](https://img.shields.io/badge/Frontend-Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)
![Supabase](https://img.shields.io/badge/Database-Supabase-3ECF8E?style=for-the-badge&logo=supabase&logoColor=white)
![GitHub Actions](https://img.shields.io/badge/CI%2FCD-GitHub%20Actions-2088FF?style=for-the-badge&logo=github-actions&logoColor=white)

---

## ğŸ“– DescripciÃ³n del Proyecto

Este repositorio aloja la plataforma integral desarrollada para la **Tesis de MaestrÃ­a en AnÃ¡lisis de Datos ClimÃ¡ticos**. El sistema permite el monitoreo, auditorÃ­a de calidad y proyecciÃ³n estocÃ¡stica de variables meteorolÃ³gicas (Temperatura y PrecipitaciÃ³n) en los estados de **Campeche, YucatÃ¡n y Quintana Roo**.

A diferencia de los tableros tradicionales, este sistema implementa una metodologÃ­a de **"Caja Blanca"**, transparentando los cÃ¡lculos matemÃ¡ticos, el anÃ¡lisis de residuos y la cinemÃ¡tica del cambio climÃ¡tico.

---

## ğŸ“‹ Tabla de Contenidos

1. [Arquitectura del Sistema](#-arquitectura-del-sistema)
2. [CaracterÃ­sticas CientÃ­ficas](#-caracterÃ­sticas-cientÃ­ficas)
3. [Estructura del Repositorio](#-estructura-del-repositorio)
4. [InstalaciÃ³n y Despliegue](#-instalaciÃ³n-y-despliegue)
5. [MetodologÃ­a de PredicciÃ³n](#-metodologÃ­a-de-predicciÃ³n)
6. [AutomatizaciÃ³n (ETL)](#-automatizaciÃ³n-etl)

---

## ğŸ— Arquitectura del Sistema

El proyecto sigue una arquitectura desacoplada moderna:

* **Ingesta (ETL):** Scripts en Python que procesan archivos `.txt` crudos (formato CONAGUA/SMN), aplican filtros geogrÃ¡ficos de seguridad y normalizan fechas.
* **Almacenamiento:** Base de datos relacional **PostgreSQL** alojada en la nube (Supabase).
* **Frontend:** AplicaciÃ³n web interactiva construida con **Streamlit**.
* **CÃ³mputo:** LibrerÃ­as cientÃ­ficas (`SciPy`, `Pmdarima`, `Statsmodels`, `NumPy`).

---

## ğŸ§ª CaracterÃ­sticas CientÃ­ficas

### 1. ğŸ—ºï¸ Mapa Interactivo de Estaciones
* VisualizaciÃ³n geoespacial con `Folium`.
* Filtrado dinÃ¡mico por entidad federativa.
* OptimizaciÃ³n de renderizado para grandes volÃºmenes de puntos.

### 2. ğŸ” AuditorÃ­a de Calidad de Datos
* **Completitud:** Tabla semafÃ³rica que calcula el % de datos vÃ¡lidos histÃ³ricos por estaciÃ³n.
* **DetecciÃ³n de Outliers:** Diagramas de Caja (Boxplots) para identificar anomalÃ­as en sensores.
* **Prueba de Normalidad:** GrÃ¡ficos Q-Q (Quantile-Quantile) con muestreo estadÃ­stico para validar la distribuciÃ³n gaussiana de los datos.

### 3. ğŸ“‰ CinemÃ¡tica ClimÃ¡tica (Derivada)
Para evaluar la velocidad del cambio climÃ¡tico local, se calcula la primera derivada de la tendencia:
$$v(t) = \frac{dT_{trend}}{dt}$$
* Permite detectar periodos de **aceleraciÃ³n** (barras rojas) o desaceleraciÃ³n (barras azules) en el calentamiento.

### 4. ğŸ”® Predicciones "Caja Blanca" (SARIMA)
Se utiliza el algoritmo `auto_arima` para minimizar el criterio AIC (Akaike Information Criterion). El sistema expone:
* **ParÃ¡metros:** $(p,d,q) \times (P,D,Q)_{12}$ explicados en lenguaje natural.
* **DiagnÃ³stico:** Histogramas y trazas de residuos para validar que el error sea "Ruido Blanco".
* **ProyecciÃ³n:** Intervalos de confianza al 95%.

---

## ğŸ“‚ Estructura del Repositorio

mi-tesis-clima/
â”‚
â”œâ”€â”€ .github/workflows/      # CI/CD: AutomatizaciÃ³n de carga de datos
â”‚   â””â”€â”€ actualizar_datos.yml
â”‚
â”œâ”€â”€ datos_climatologicos_diarios/ # Datos crudos (Input)
â”‚   â”œâ”€â”€ CAMP/
â”‚   â”œâ”€â”€ YUC/
â”‚   â””â”€â”€ QROO/
â”‚
â”œâ”€â”€ pages/                  # MÃ³dulos de la aplicaciÃ³n
â”‚   â”œâ”€â”€ Calidad_Datos.py    # AuditorÃ­a, Outliers y Q-Q Plots
â”‚   â”œâ”€â”€ Estadisticas.py     # Climogramas y Tendencias lineales
â”‚   â””â”€â”€ Predicciones.py     # Modelo SARIMA y CinemÃ¡tica
â”‚
â”œâ”€â”€ etl_supabase.py         # Script ETL (ExtracciÃ³n, TransformaciÃ³n y Carga)
â”œâ”€â”€ Inicio.py               # Homepage (Mapa Interactivo)
â”œâ”€â”€ utils.py                # ConexiÃ³n a BD y CachÃ©
â”œâ”€â”€ requirements.txt        # Dependencias del proyecto
â””â”€â”€ README.md               # DocumentaciÃ³n

## ğŸ’» InstalaciÃ³n y Despliegue

### Requisitos Previos
- Python 3.10 o superior.
- Cuenta en Supabase (PostgreSQL).

**Paso 1: Clonar**
```bash
git clone [https://github.com/TU_USUARIO/TU_REPO.git](https://github.com/TU_USUARIO/TU_REPO.git)
cd TU_REPO
```

**Paso 2: Entorno Virtual**
```bash
# Windows
python -m venv .venv
.venv\Scripts\activate

# Mac/Linux
python3 -m venv .venv
source .venv/bin/activate
```
**Paso 3: Dependencias**
```bash
pip install -r requirements.txt
```

**Paso 4: Variables de Entorno**
Crea un archivo ```.env``` en la raÃ­z (no lo subas a GitHub) con tu credencial:
```
DB_CONNECTION_STRING="postgresql://postgres:[TU_PASSWORD]@[TU_HOST]:5432/postgres"
```

**Paso 5: Ejecutar**

```bash
streamlit run Inicio.py
```

## ğŸ¤– AutomatizaciÃ³n (ETL)
La base de datos se mantiene actualizada mediante GitHub Actions.

- Archivo: .github/workflows/actualizar_datos.yml

- Frecuencia: Semanal (Lunes 00:00 UTC).

- Proceso:

  1. Levanta un contenedor Ubuntu.

  2. Ejecuta etl_supabase.py.

  3. Aplica filtros de seguridad geogrÃ¡fica (elimina coordenadas errÃ³neas fuera de la penÃ­nsula).

  4. Sube los nuevos datos a Supabase.

**Autor:** JosÃ© Emiliano Flores PÃ©rez

Desarrollado como parte de mi proyecto de Tesis de MaestrÃ­a junto a PROFEPA.